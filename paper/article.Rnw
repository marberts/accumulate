\documentclass[article,table]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------
%% recommended packages
\usepackage{orcidlink,thumbpdf,lmodern}

\usepackage{amsmath, amssymb}
\usepackage[ruled, linesnumbered]{algorithm2e}



%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}



%% For Sweave-based articles about R packages:
%% need no \usepackage{Sweave}
\SweaveOpts{engine=R, eps=FALSE, keep.source = TRUE}
<<preliminaries, echo=FALSE, results=hide>>=
options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
@


%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation (and optionally ORCID link)
%% - \Plainauthor{} without affiliations
%% - Separate authors by \And or \AND (in \author) or by comma (in \Plainauthor).
%% - \AND starts a new line, \And does not.
\author{Mark P.J. van der Loo~\orcidlink{0000-0002-9807-4686}\\
        Statistics Netherlands and University of Leiden}

\Plainauthor{Mark P.J. van der Loo}

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{Split-Apply-Combine with Collapsing Groups}
\Plaintitle{Split-Apply-Combine with Collapsing Groups}
\Shorttitle{Split-Apply-Combine with Collapsing Groups}


\Abstract{
foo
}

%% - \Keywords{} with LaTeX markup, at least one required
%% - \Plainkeywords{} without LaTeX markup (if necessary)
%% - Should be comma-separated and in sentence case.
\Keywords{data analysis, \proglang{R}}
\Plainkeywords{data analysis, R}

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).
\Address{
  Mark P.J. van der Loo~\orcidlink{0000-0002-9807-4686}\\
  Research and Development\\
  Statistics Netherlands\\
  Henri Faasdreef 312\\
  2492JP Den Haag, the Netherlands\\
  E-mail: \email{mpj.vanderloo@cbs.nl}\\
  URL: \url{https://www.markvanderloo.eu}\\
  \emph{and}\\
  Leiden Institute of Advanced Computer Science (LIACS)\\
  P.O. Box 9512\\
  2300 RA Leiden, The Netherlands\\
}

\begin{document}


%% -- Introduction -------------------------------------------------------------

%% - In principle "as usual".
%% - But should typically have some discussion of both _software_ and _methods_.
%% - Use \proglang{}, \pkg{}, and \code{} markup throughout the manuscript.



\section{Introduction}
The operation of splitting a data set into non-overlapping groups, computing an
aggregate for each group, and combining the results into a new dataset is one
of the most common operations in data analyses. Indeed, any software for data
analyses includes some functionality for this. For example, the combination of
\code{split}/\code{lapply}/\code{unsplit} as well as \code{aggregate} have been
a part of the \proglang{S} \citep{becker1988new} and \proglang{R} \citep{rcore}
languages for a long time. For \proglang{R} there are several packages that
implement functionality for this, including \pkg{plyr}
\citep{wickham2011split}, it's successor \pkg{dplyr} \citep{wickham2022dplyr},
it's drop-in replacement \pkg{poorman} \citep{eastwood2022poorman}, and
\proglang{R} packages \pkg{collapse} \citep{krantz2022collapse} and
\pkg{data.table} \citep{dowle2022datatable}. In \proglang{Python} the
\code{pandas} package implements several methods for grouping records and
aggregating over one or more columns in data frame objects. Similarly, the
\pkg{DataFrames} package for \proglang{julia} implements such functionality
\citep{kaminski2022dataframes}.

In all packages mentioned, the calculation for each group uses data available
within the group. However, there are valid use cases where a group aggregate is
determined using attributes from out-of-group entities. One example where this
occurs is in the area of small area estimation (see e.g.
\citet{molina2015sae}. Here, one wishes to estimate an aggregate for a group,
for example a geographical region, or a detailed population subset, where the
number of (sampled) observations so small that the variance of the estimate
would be unacceptably large. Small area estimation is a collection of
bias-variance trade-offs where one `borrows statistical strength' from
out-of-group records to obtain a stable estimate for groups with few
observations. The out-of-group records can be obtained, for example by
combining the original group with a group of records that are deemed similar in
certain respects. A second area where out-of-group records play a role is in
certain hot-deck imputation methods \cite{andridge2010review}.  In
$k$-nearest-neighbours imputation for example, one finds a set of $k$ donor
records that are preferably in the same group, but this condition may be
relaxed if there are not enough records in the group. In the \pkg{VIM} package
for \proglang{R} \citep{kowarik2016imputation}, this is controlled by a
combination of the Gower distance and setting conditions on minimal number of
donors. A third example comes from the field of statistical disclosure control
\citep{hundepool2012statistical}. In this field, the so-called $p$\% rule states
that the value in a grouped aggregation may not be determined for more than $p$
percent by a single entity. This occurs for example, when a certain economic
activity in a geographic region is dominated by a single company. In such cases
the value can either not be published, or one publishes an aggregate over
larger groups.





 





Common quality issues
include insufficient records, or too many records with values for certain
variables missing. In such cases it is not uncommon to use data from outside
the target group  to estimate the group aggregate. One example is Small Area
Estimation, where the lack of observations in one group is compensated by using
data from similar but other groups. Another area where such approaches occur is
group-wise imputation. For example, one may wish to impute a group estimate
(say, mean, or median) for missing values. If there are too little observations
to provide an accurate estimate of the group mean, the group may be expanded,
trading bias for variance. 



\begin{itemize}
\item Add SDC collapsing as application
\end{itemize}

One approach that frequently occurs in practice is to use a so-called
collapsing scheme. In this approach one attempts to estimate the aggregate for
the most fine-grained grouping first.  If this is not possible, two or more
groups are combined to provide input for estimating a value for the
fine-grained group. The collapsing scheme defines which groups may be combined,
and it may consist of multiple levels of collapsing; in principle to the point
where the whole data set is used to estimate an aggregate value for a single
group.

Collapsing schemes can be the result of an optimisation, but they frequently
result from subject matter as well. For example, in the case of hierarchical
classifications, there is a natural ordering of groups that are similar from a
subject matter point of view (whether that means that they can be considered
representative for each other is another, statistical, question).  Examples
include the NACE classification of economic activities or the ISCO
classification of professions. Both have a tree-like structure that can be used
to combine groups with a common ancestor in the hierarchy.

In this paper we formalise the concept of `collapsing scheme', and give an
algorithm for split-apply-combine operations based on it. Next, we demonstrate
the R package \texttt{accumulate} that implements this algorithm together with
some utility functions that make working with collapsing schemes easier.



\section{Formal descriptions and algorithms}
In this section we give a formal description of the algorithms. In order to be
unambiguous and to represent the algorithms compactly, we introduce some
notation. The notation also makes the pseudocode independent of the
implementation language used, or how the data is represented. 

We start by giving the algorithm for ordinary split-apply-combine, so it is
easy to see where the algorithm must be generalized to allow for a collapsing
scheme.


\subsection{Split-apply-combine}
In order to analyse a data set group by group we need to specify a data set, a
way to split it into groups, and a function that takes a subset of data and
returns an aggregate. Let us introduce some notation for that.

Let $U$ be a finite set, and let $\phi$ be a function that accepts a subset of
$U$ and returns a value in some domain $X$. Here, $U$ represents a data set and
$\phi$ an aggregating function. We split $U$ into groups using the following
notation. Let $A$ be finite set that has no more elements than $U$, and let $f$
be a function that takes an element of $U$ and returns a value in $A$. We can
think of $A$ as a set of group labels, and $f$ as the function that assigns a
label to each element of $U$. This way, $f$ divides $U$ into non-overlapping
groups, since every element in $U$ can only get one label.  In formal
terminology we say that $f:U\to A$ is a \emph{partition} of $U$.

In this notation, any split-apply-combine operation can be computed with the
following algorithm.

\begin{algorithm}[H]
\caption{Split-Apply-Combine}
\label{alg:sac}
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\Input{A finite set $U$, an aggregator $\phi: 2^U\to X$, and a partition $f:U\to A$}
\Output{$R$: the value of $\phi$ for every part of $U$ as a set of pairs $(a,x)\in
A\times X$ }

$R = \{\}$\;
\For{$a\in A$}{
  $d=f^{-1}(\{a\})$\tcp*{get subset of $U$}
  $R = R\cup \{(a,\phi(d))\}$\tcp*{aggregate and add to result}
}
\end{algorithm}

Here, the output is collected in a set $R$ (this set is technically a function
$A\to X$ since it pairs for each $a\in A$ with one element of $X$). We also
introduced some new notation: the notation $2^U$ stands for `the set of all
subsets of $U$'. The notation $f^{-1}$ stands for the formal \emph{inverse} of
$f$. That is: you give it a set of labels from $A$ and it returns all the
elements of $U$ that have any of those labels. This definition is slightly too
general for the current algorithm, but it will come in handy when we move to
collapsing groups.

Let us see how the elements $U$, $f:U\to A$, and $\phi$ are implemented
in practice. Consider the signature of the R \texttt{aggregate} function for data
frames (we skip arguments that are not important for the discussion).
\begin{verbatim}
  aggregate(x, by, FUN)
\end{verbatim}
Here, \texttt{x} is a data frame where each column is a variable $U$ to be
aggregated.  The argument \texttt{by} represents the record-wise label(s) that
are used for grouping. So the function $f\to A$ is implemented by forcing the
user to make sure that the position of each label in \texttt{by} corresponds to
the row number in the data frame \texttt{x}. The argument \texttt{FUN} is the
function $\phi$ that aggregates each subset of \texttt{x}.  Here is an example of how
a user might call this function from the R prompt.
%
\begin{verbatim}
> aggregate(iris["Sepal.Length"], by=iris["Species"], FUN=mean)
     Species Sepal.Length
1     setosa        5.006
2 versicolor        5.936
3  virginica        6.588
\end{verbatim}
%
Note that the correspondence in position of the \texttt{Species} label and the
record position is implemented by taking them from the same data frame. The output
also reveals in the first column the set $A$: each row corresponds to a unique
value in \texttt{Species} column.


\subsection{Split-apply-combine with collapsing groups}
\label{sect:saccg}
The goal of the algorithm is to compute a value for each part of a dataset,
possibly using values from a larger subset. The input of the algorithm consists
again of a finite set $U$ and an aggregation function $\phi$ that takes a subset
of $U$ and returns a value in some domain $X$.  Compared to
Algorithm~\ref{alg:sac} we need two extra inputs. First, we need a user-defined
function that checks whether a given subset $d$ of $U$ is suitable for
computing $\phi(d)$.  We will call this function $\beta: 2^U\to \mathbb{B}$,
where $\mathbb{B}=\{\texttt{True},\texttt{False}\}$.  Typical tests are
checking whether there are sufficient records available, or whether certain
variables have a low enough fraction of missing values. Second, we need a
\emph{collapsing scheme}
\begin{equation}
U\xrightarrow{f_0}A_0\xrightarrow{f_1}A_1\xrightarrow{f_2}\cdots\xrightarrow{f_n}A_n.
\label{eq:collapsingsequence}
\end{equation}
A collapsing scheme is a sequence of partitions where each $f_i:A_{i-1}\to A_i$
partitions $A_{i-1}$ into $|A_i|$ groups. 

Collapsing schemes can be represented as tables. For example, the European NACE
classification is a hierarchical classification of economic activity. Each
group is encoded as a 4-digit code where the first digit indicates the highest
grouping level, and the last digit the most detailed level. This induces a
collapsing sequence by combining groups that have the same parent in the
hierarchy. Below is an example, based on a small piece of the NACE code list.
%
\begin{table}[h!]
\begin{tabular}{rrr}
\hline
 $A_0$& $A_1$ & $A_2$\\
\hline
0111&   011 & 01\\
0112&   011 & 01\\
0113&   011 & 01\\
0121&   012 & 01\\
0122&   012 & 01\\
0123&   012 & 01\\
0124&   012 & 01\\
\hline
\end{tabular}
\label{eq:tablerep}
\end{table}

Here, $A_0$ is the most detailed partition, splitting a dataset into seven
groups, relating to $\{0111,\ldots,0124\}$. In $A_1$ there are two groups.
The first, labeled $01.1$ is constructed by combining $0111, 0112$ and
$0113$ and the second, labeled $01.2$ is constructed by combining
$0121,\ldots 01.24$. Finally, in $A_2$ all groups are combined.

To compute an aggregate for records labeled with $0111$, the algorithm will
select those records and test whether the subset is suitable. If not, it will
move to $f_1(0111)=011$ and find all the groups in $A_0$ that map to 011 as
follows.
\begin{displaymath}
f_1^{-1}(\{011\}) = \{0111, 0112, 0113\}.
\end{displaymath}
It will then move on and find all records labeled with any of those three
group labels, and test again. If this new data set is suitable, the result is
computed, if not, another collapse takes place. The whole procedure is repeated 
for each element in $A_0$.




In order to generalize this algorithm towards generic collapsing schemes, we
introduce the function $F_k:A_0\to A_k$, which accepts a label in $A_0$ and
returns the corresponding label in $A_k$. This can formally be defined as
consecutive application of $f_1, f_2,\cdots, f_k$ to an element of $A_0$. In
notation
\begin{equation*}
F_k \equiv f_k\circ f_{k-1}\circ\cdots\circ f_1.
\end{equation*}
Similarly we define $F^{-1}_k:2^{A_k}\to 2^{A_0}$ as the composition
\begin{equation*}
F_k^{-1} \equiv f_1^{-1}\circ f_2^{-1}\circ\cdots\circ f_k^{-1}.
\end{equation*}
This function asks for a set of labels in $A_k$ and returns all the labels in
$A_0$ that are mapped to those labels via the collapsing sequence of
Equation~\eqref{eq:collapsingsequence}.  We are now ready to formally write
down our main Algorithm~\ref{alg:saccg}.

%
\begin{algorithm}[H]
\caption{Split-Apply-Combine with Collapsing Groups}
\label{alg:saccg}
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\Input{A finite set $U$, an aggregator $\phi: 2^U\to X$, a test function $\beta: 2^U\to \mathbb{B}$,
      and a collapsing sequence $U\xrightarrow{f_0}A_0\cdots \xrightarrow{f_n}  A_n$}

\Output{$R$: the value of $\phi$ for every part of $U$, for which a suitable
collapsing group can be found, as a set of triples $(a,k,x)\in A_0\times
\underline{n}\times X $ where $\underline{n}=\{0,1,\ldots,n\}$.}

$R = \{\}$\;
\For{$a\in A_0$}{
  $i=0$\;
  $d = f_0^{-1}(\{a\})$\tcp*{get subset of $U$}
  \While{$i<n \land \lnot\beta(d)$}{
    $i = i+1$ \tcp*{Increase collapse level} 
    $d = (f_0^{-1}\circ F_i^{-1}\circ F_i)(a)$ \tcp*{Collapse and get subset}
  }
  \If{$i<n \lor \beta(d)$}{ \label{line:cond}
    $R = R\cup \{(a, i,\phi(d))\}$\;
  } 
}

\end{algorithm}
%
Since the used level of collapsing is determined dynamically by data
circumstances in $U$, the algorithm also reports the collapsing level used to
compute a value foe each member of $A_0$. For each member of $A_0$ there is a
triple $(a,i,\phi(d))$, where $a\in A_0$ is the label to which the value
$\phi(d)$ pertains, and $i$ is the number of collapses applied to reach a
suitable dataset. The condition in Line~\ref{line:cond} ensures that if no
suitable dataset is found after the whole collapsing sequence has been
executed, then no answer is returned.



\subsection{Caveat: unbalanced hierarchical classifications}
\begin{itemize}
\item tree with different levels of details
\end{itemize}


\section{The accumulate R package}
Grouped aggregation with a fall-though scenario based on a collapsing scheme
requires a lot of parameters to be specified by the user. Besides the data, one
needs to specify the method(s) of aggregation, the collapsing scheme, and the
condition to decide whether a subset is fit for aggregation or a next collapse
is necessary. The main function of the package is caled \texttt{collapse}
and has the following signature.
\begin{verbatim}
  accumulate(data, collapse, test, ...)
\end{verbatim}
where \texttt{data} is a data frame, \texttt{collapse} represents the collapse
sequence, \texttt{test} is a function that accepts a subset of \texttt{data}
and returns \texttt{TRUE} or \texttt{FALSE} and the ellepsis is a sequence
of \texttt{label = expression} pairs that represent aggregation
functions, in a similar style as \texttt{dplyr::summarize}. The output
is a data frame that can schematically be represented as follows.
\begin{verbatim}
  [Grouping Variables, Collapse level, Output aggregates]
\end{verbatim}
The first columns represent the variables that define the output grouping, the
next column is an integer that indicates the level of collapsing used to
compute the aggregate, and the last set of columns store the aggregates.

To accommodate the different use cases, the \pkg{accumulate} package supports
two different interfaces for specifying collapse sequences.  The first and most
general is the formula interface, that requires that the collapsing sequence is
represented as variables in the data set to be aggregated. The second is the
tabular interface discussed before. This only supports a single grouping
variable. For hierarchical classifications there is a helper function to
translate parent-child representations of such classifications into a
collapsing sequence.

Besides complicated collapsing schemes, users must have the ability to specify
a possibly complex condition for determining when a dataset is suitable for
aggregation or not. The package offers some convenience functions that support common
use cases as well as support for specifying generic conditions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The formula interface}
It is not uncommon for users to use multiple variables for defining collapsing
schemes. For example when grouping by two categorical variables \texttt{A} and
\texttt{B}, one may first want to collapse variable $\texttt{B}$ into a
variable \texttt{B1} and if that is not sufficient, in the next step grouping
in the second variable is dropped so grouping is only defined by \texttt{A}.
In \pkg{accumulate} such a scheme is denoted with the formula \texttt{A*B \~{}
A*B1 + A}. Here, the left-hand-side denotes the desired output grouping level
that is attempted first, and the right-hand-side denotes consecutive collapse
levels separated by \texttt{+}.

The following tables illustrate the idea. The left table represents the data
set to be aggregated by \texttt{A} and \texttt{B}. In this example we wish to
compute the sum $t_Y$ of column $Y$ per group. We demand that there are at
least three records in a group, otherwise we collapse one step.
%
\begin{center}
\begin{tabular}{cccl}
\multicolumn{4}{l}{\texttt{Input data}}\\
\hline
\texttt{A} & \texttt{B} & \texttt{B1} & $Y$\\
\hline
\cellcolor{red!25}   1 &\cellcolor{red!25}   11 &                1       & \cellcolor{red!25}   1   \\
\cellcolor{red!25}   1 &\cellcolor{red!25}   11 &                1       & \cellcolor{red!25}   2   \\
\cellcolor{red!25}   1 &\cellcolor{red!25}   11 &                1       & \cellcolor{red!25}   4   \\
\cellcolor{green!25} 2 &                     12 & \cellcolor{green!25} 1 & \cellcolor{green!25} 8   \\
\cellcolor{green!25} 2 &                     12 & \cellcolor{green!25} 1 & \cellcolor{green!25} 16  \\
\cellcolor{green!25} 2 &                     13 & \cellcolor{green!25} 1 & \cellcolor{green!25} 32  \\
\cellcolor{blue!25}  3 &                     21 &                2       & \cellcolor{blue!25}  64  \\
\cellcolor{blue!25}  3 &                     22 &                2       & \cellcolor{blue!25}  128 \\
\cellcolor{blue!25}  3 &                     12 &                1       & \cellcolor{blue!25}  256 \\
\hline
\end{tabular}\hspace{1cm}\begin{tabular}{ccl}
\multicolumn{3}{l}{\texttt{Output}}\\
\hline
\texttt{A*B} & \texttt{level} & $t_Y$\\
\hline
\rowcolor{red!25}   1 11        & 0             & 7  \\
\rowcolor{green!25} 2 12        & 1             & 56 \\
\rowcolor{green!25} 2 13        & 1             & 56 \\
\rowcolor{blue!25}  3 21        & 2             & 448\\
\rowcolor{blue!25}  3 22        & 2             & 448\\
\rowcolor{blue!25}  3 12        & 2             & 448\\
\hline
\end{tabular}
\end{center}
%
The table on the right represents the output. Colors indicate which data was
used. The First row in the output represents group
$(\texttt{A}=1,\texttt{B}=11)$. The collapsing level is zero, which means
that no collapsing was necessary. Indeed, in the data table we see that there
are three rows with \texttt{A==1} and \texttt{B==11} with $Y$ values $1, 2$,
and $7$, resulting in $t_Y=7$ for this group.

Next, the algorithm tries to compute the total for group
$(\texttt{A}=2,\texttt{B}=12)$ (in green) but finds that there are only two
such rows. It now defines a new group $(\texttt{A}=2,\texttt{B1}=1)$ and finds
that there are three records in that group so it computes $t_Y=8+16+32=56$.
Similarly, it finds one record with $(\texttt{A}=2,\texttt{B}=13)$ and
collapses to $(\texttt{A}=2,\texttt{B1}=1)$, again yielding $t_y=56$.

Finally, for $(\texttt{A}=2,\texttt{B}=21)$ the algorithm finds only a single
record. It collapses to $(\texttt{A}=2,\texttt{B1}=2)$ and finds two so it
collapses further to $(\texttt{A}=2)$ to find three records.  This yields
$t_Y=64+128+256=448$. Similarly, the groups $(\texttt{A}=3, \texttt{B}=22)$ and
$(\texttt{A}=3,\texttt{B}=12)$ are collapsed to $(\texttt{A}=2)$.

In R code the previous example can be executed as follows.
\begin{verbatim}
  > library(accumulate)
  > input <- data.frame(
  +      A  = c(1,1,1,2,2,2,3,3,3)
  +    , B  = c(11,11,11,12,12,13,21,22,12)
  +    , B1 = c(1,1,1,1,1,1,2,2,1)
  +    , Y  = 2^(0:8)
  + )
  >
  > collapse(data     = input
  +        , collapse = A*B ~ A*B1 + A
  +        , test     = function(d) nrow(d)>=3
  +        , tY       = sum(Y) )
    A  B level  tY
  1 1 11     0   7
  2 2 12     1  56
  3 2 13     1  56
  4 3 21     2 448
  5 3 22     2 448
  6 3 12     2 448
\end{verbatim}
%
The formula interface allows users to quickly experiment with different
collapsing schemes, but only after the necessary variables have been added to
the original data frame, which may require some extensive data manipulation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The data frame interface}
\eqref{eq:tablerep}




\subsection{Specifying tests}

\subsection{Programming over accumulate }

\section{Extensive example: imputing economic data}

\section{Summary and conclusion}

\begin{itemize}
\item{Record-wise results}
\item{Record-wise imputation}
\item{Representation of hierarchical classifications: parent-child lists vs tabular}
\end{itemize}

\bibliography{refs}




\end{document}
